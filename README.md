## Способ 1. Эвристический подход

1. Взять 2 серии одного сериала (например, https://vkvideo.ru/video-220020068_456255400 и https://vkvideo.ru/video-220020068_456255401);
2. Разбить первые две минуты видеоряда на кадры с частотой 1 кадр в секунду;
3. Хэшировать каждый кадр с помощью [ImageHash](https://pypi.org/project/ImageHash/);
4. Сравнить хэши кадров двух видео.

```python
import cv2
import imagehash
from PIL import Image

def Diff_img(img0, img):
    hash1 = imagehash.average_hash(Image.fromarray(img0))
    hash2 = imagehash.average_hash(Image.fromarray(img))
    if hash1 == hash2:
        return 1
    else:
        return 0


video1 = "data_train_short/-220020068_456255400/-220020068_456255400.mp4"
cap1=cv2.VideoCapture(video1)

video2 = "data_train_short/-220020068_456255401/-220020068_456255401.mp4"
cap2=cv2.VideoCapture(video2)

Result = []
num_of_frames = 0
Seconds = 0
while True:
    ret1,frame1=cap1.read()
    ret2,frame2=cap2.read()

    if num_of_frames % 24 == 0:   # работаем с каждым 24-м кадром, т.к. fps=24
        Result.append(Diff_img(frame1, frame2))
        Seconds += 1
    num_of_frames += 1

    if Seconds == 60:
        break

print(Result)   # вывод списка, где i-й элемент равен 1 в случае совпадения i-х кадров и равен 0 в противном случае
```
**Достоинства метода:**
- Быстродействие;
- Отсутствие необходимости в обучении модели.

**Недостатки:**
- Метод работает только с парой видео с одинаковой структурой (т.е. такими, у которых заставка находится примерно в одинаковом месте);
- Метод обнаруживает не только заставку сериала, но и другие заставки при их наличии (например, заставку Netflix).

---

## Способ 2. CLIP + Multi-head attention

Задача решается как последовательная бинарная классификация:

>Каждой секунде видео присваивается метка 1 или 0, где 1 - метка заставки, 0 - метка основного контента.

Данный способ подходит и для видео, в которых нет заставки.

1. Очистим датасет от выбросов. 

    В данных присутствуют выбросы (в основном в тех видео, в которых нет заставки) - таймкод начала обозначен раньше таймкода конца:

```json
"-220020068_456255332": {
    "url": "https://vkvideo.ru/video-220020068_456255332",
    "name": "Агентство Локвуд и компания. 1 сезон. 3 серия.",
    "start": "0:02:57",
    "end": "0:02:25"
    },
```

2. Разбиваем видео на кадры с частотой 1 кадр в секунду и сжимаем до 224х224 пикселей (формат ImageNet).
3. Подаём на вход предобученной модели CLIP последовательность из нескольких кадров для извлечения признаков.
4. Добавляем к полученным эмбеддингам позиционные эмбеддинги с целью сохранения упорядоченности кадров.
5. Используем механизм multi-head attention для обнаружения долгосрочных зависимостей между кадрами.
6. На выходе каждый кадр проходит через бинарный классификатор (сигмоиду).

Референс: [Automatic Detection of Intro and Credits in Video using CLIP and Multihead Attention](https://arxiv.org/pdf/2504.09738v1)
